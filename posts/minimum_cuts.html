<!DOCTYPE html>
<html lang="en">
<head>
<!-- 2023-02-23 Thu 22:29 -->
<meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Minimum cut algorithms</title>
<meta name="author" content="Luca Zaninotto" />
<meta name="generator" content="Org Mode" />
<link rel="stylesheet" type="text/css" href="https://gongzhitaao.org/orgcss/org.css"/>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        displayAlign: "center",
        displayIndent: "0em",

        "HTML-CSS": { scale: 100,
                        linebreaks: { automatic: "false" },
                        webFont: "TeX"
                       },
        SVG: {scale: 100,
              linebreaks: { automatic: "false" },
              font: "TeX"},
        NativeMML: {scale: 100},
        TeX: { equationNumbers: {autoNumber: "AMS"},
               MultLineWidth: "85%",
               TagSide: "right",
               TagIndent: ".8em"
             }
});
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML"></script>
</head>
<body>
<div id="preamble" class="status">
<nav><a id="navbar-home" href="../index.html">üè°  Home</a></nav>
</div>
<div id="content" class="content">
<h1 class="title">Minimum cut algorithms</h1>

<div id="outline-container-org7ea3ce4" class="outline-2">
<h2 id="org7ea3ce4">Intro</h2>
<div class="outline-text-2" id="text-org7ea3ce4">
<p>
Networks are everywhere, and they come in all shapes and sizes. From
social networks to transportation networks, there's always a need to
find the most efficient way to move data or resources through
them. This is where minimum cut algorithms come in. These algorithms
are designed to identify the smallest set of edges in a network
that, when removed, disconnects the graph into two or more smaller
subgraphs. However, with so many different minimum cut algorithms
available, it can be challenging to know which one to choose for a
particular problem. In this blog post, we will compare and contrast
two popular minimum cut algorithms, the Karger and Stein algorithm
and the Stoer and Wagner algorithm, and also introduce an exciting
hybrid approach that combines the strengths of both. By the end of
this post, you'll have a better understanding of which algorithm is
best suited for your network optimization needs.
</p>
</div>
<div id="outline-container-org4645604" class="outline-3">
<h3 id="org4645604">Implementation</h3>
<div class="outline-text-3" id="text-org4645604">
<p>
Implementation of the algorithms described here can be found on
<a href="https://github.com/badadumTss/karger_stein">GitHub</a>, the provided code is the same one that generated the data
in order to make comparisons on runtime
</p>
</div>
</div>
</div>
<div id="outline-container-orgae1f800" class="outline-2">
<h2 id="orgae1f800">The problem</h2>
<div class="outline-text-2" id="text-orgae1f800">
<p>
The problem we want to solve is to find a cut of a graph such that
its weight is minimal. In other words, given a graph
</p>

<p>
\[G = (V, E)\]
</p>

<p>
where \[V = \{1,2,3,\dots,n\}\] is a set of \(n\) vertices and \[E \subseteq
  \{(u,v) \mid u,v \in V\}\] a set of \(|E| = m\) edges and a function
</p>

<p>
\[ w : E \rightarrow \mathbb{R} \]
</p>

<p>
a <i>cost</i> function, that returns the weight of each edge, we want to
find
</p>

<p>
\[p_1, p_2 \subseteq V \mid p_1 \cap p_2 = \emptyset \, , \, p_1 \cup p_2 = V\]
</p>

<p>
such that
</p>

<p>
\[\text{cost}(p_1, p_2) = \sum_{u \in p_1, v \in p_2} w((u,v))\]
</p>

<p>
is minimized.
</p>
</div>
</div>

<div id="outline-container-org4cb32da" class="outline-2">
<h2 id="org4cb32da">Karger and Stein</h2>
<div class="outline-text-2" id="text-org4cb32da">
<p>
<a id="org937bfa8"></a>
Karger and stein works by joining subsets of nodes, until only two
remain. Those two are a cut of the graph. More in detail, given a
Graph \(G = (V,E)\) where \(V = \{1,2,3,4,\dots,n\}\) is the set of
vertices, the algorithm starts with a partition of \(V\) where each
node appears by itself
</p>

<p>
\[\{\{1\}, \{2\}, \{3\}, \dots \{n\}\}\]
</p>

<p>
Then, let \(\mathcal{P}_a(V)\) be the set of partitions of \(V\), a
<code>contraction</code> procedure joins two subsets and produces a new
partition of \(V\).
</p>

<p>
\[\text{contraction} : \mathcal{P}_a(V) \longrightarrow \mathcal{P}_a(V)\]
</p>

<p>
This keeps happening, until the partition of \(V\) is made of only
two sets \(p_1, p_2\). At this stage the sum of the weights that
between the two nodes (the cut of the graph) is returned. This works
because of the way in which the <code>contraction</code> procedure selects the
nodes to join in the partitions. The two nodes are selected based on
a random selection based on the weight of the nodes. Nodes with an
higher weight have an higher probability of being selected.
</p>

<p>
Doing such procedure, allows to find a minimum cut with probability
\(\frac{1}{\log(n)}\), therefore by repeating this procedure
\(O(\log^2(n))\) times we can find a minimum cut with error probability
less than \(\frac{1}{n}\).
</p>

<p>
Karger and Stein implemented as such has a complexity of
</p>

<p>
\[O(n^2\log^3(n))\]
</p>
</div>

<div id="outline-container-orgc2ff11b" class="outline-3">
<h3 id="orgc2ff11b">Another bound</h3>
<div class="outline-text-3" id="text-orgc2ff11b">
<p>
Another bound for Karger and Stein is possible to achieve, if we
consider that early contractions in the <code>contraction</code> procedure are
much less likely to contract on the minimum cut.
</p>

<p>
We call \(X_i\) the event that no edge of the minimum cut is
contracted during the i-th iteration. We can define
</p>

<p>
\[X = \sum_{i=0}^k X_i\]
</p>

<p>
We know from the analysis of the algorithm that by contracting to
\(t = \frac{n}{\sqrt{2}} + 1\) nodes the probability of contracting
the minimum cut in this process is
</p>

<p>
\[P(n) \geq \frac{1}{2}\]
</p>

<p>
which means the probability of success at the i=th iteration is at
least \(\frac{1}{2}\)
</p>

<p>
\[P(X_i = 1) \leq \frac{1}{2}\]
</p>

<p>
We want to find \(k\) such that our our random variable \(X\) (the
sum of the <i>success</i> of each iteration) does not go ``too far
away'' from the mean value \(\mu\)
</p>

<p>
\[\mu = E[X] = \sum_{i=0}^k E[X_i] = \frac{k}{2}\]
</p>

<p>
since \(X_i\)s are independent random indicator variables.
</p>

<p>
so we want to find
</p>

<p>
\[P\left(\left|X-\mu\right| < \epsilon \mu\right) = 1 - P\left(
   \left| X-\mu \right| > \epsilon \mu\right) \]
</p>

<p>
and we know by chernoff bound that
</p>

<p>
\[P\left(\left| X - \mu \right| > \epsilon \mu\right) \leq
   2e^{-\frac{\mu\epsilon^2}{3}} \quad \text{for } 0 < \epsilon \leq
   1\]
</p>

<p>
by replacing \(\mu = \frac{k}{2}\)
</p>

<p>
\[P\left(\left| X - \frac{k}{2} \right| > \epsilon
   \frac{k}{2}\right) \leq 2e^{-\frac{\frac{k}{2}\epsilon^2}{3}} \quad
   \text{for } 0 < \epsilon \leq 1\]
</p>

<p>
and therefore by choosing \(k = \frac{6}{\epsilon^2}\log(n) =
   O(\log(n))\) we have that
</p>

<p>
\[P\left(\left| X - \mu \right| > \epsilon \mu\right) \leq
   \frac{2}{n} = O\left(\frac{1}{n}\right)\]
</p>

<p>
and so
</p>

<p>
\[P\left(\left|X-\mu\right| < \epsilon \mu\right) = 1 - O \left(
   \frac{1}{n}\right)\]
</p>

<p>
therefore, for \(k = O\left(\log(n)\right)\) the algorithm gives a
correct result with high probability with a complexity of
</p>

<p>
\[O\left(n^2 \log^2(n)\right)\]
</p>
</div>
</div>

<div id="outline-container-org9629ba7" class="outline-3">
<h3 id="org9629ba7">Results</h3>
<div class="outline-text-3" id="text-org9629ba7">

<div id="org4c9a0a3" class="figure">
<p><img src="./imgs/Karger and Stein.png" alt="Karger and Stein.png">
</p>
<p><span class="figure-number">Figure 1: </span>Karger and Stein run times against input size (number of vertices)</p>
</div>

<p>
The function plotted is the complexity of the algorithm. The
coefficient for the surface (under which all results should fall)
is calculated as
</p>

<p>
\[\max \left( \frac{t}{n^2\log^2(n)} \right) \]
</p>

<p>
since the time of execution of the algorithm is maximized by this
function and the different coefficient depend also on external
factors (CPU throttle, memory allocations, etc.) and we're
interested the behavior of the algorithm against the input
nodes. As we can see in Figure <a href="#org4c9a0a3">1</a> the run times follow
the surface of the complexity function.
</p>
</div>
</div>
</div>

<div id="outline-container-orga613dcb" class="outline-2">
<h2 id="orga613dcb">Stoer and Wagner</h2>
<div class="outline-text-2" id="text-orga613dcb">
<p>
Stoer and Wagner works in another way. Instead of relying on random
cuts relies on the fact that given a couple of nodes, They either
are separated by the minimum cut or are on the same side of the
cut. So given a graph \(G=(V,E)\), \(s,t \in V\), an \(s,t\) minimum
cut is a cut \((S,T)\) of \(G\) s.t.
</p>

<p>
\[s\in S \vee t\in T\]
\[w(S,T) \text{ is minimum among all \(s,t\) cuts}\]
</p>

<p>
So, let \((S,T)\) be a global min-cut for \(G\). For every pair
\(s,t \in V\) either \(s\in S\) and \(t\in T\) or \(s\) and \(t\)
are on the same side of the cut.
</p>

<p>
Stoer and wagner leverages this fact and searches for \(s,t \in V\)
s.t. \((S, T)\) is a global min cut for \(G\). If that's also a
global min-cut its weight is returned, otherwise the global min-cut
for \(G\backslash\{s,t\}\) (The same graph as \(G\), where the nodes
\(s\) and \(t\) are merged together) is also a global min-cut for
\(G\).
</p>
</div>

<div id="outline-container-org5f68456" class="outline-3">
<h3 id="org5f68456">Results</h3>
<div class="outline-text-3" id="text-org5f68456">
<p>
The complexity of this algorithm is
</p>

<p>
\[O(mn \log(n))\]
</p>

<p>
where \(n = |V|\) and \(m = |E|\). so the coefficient for the plot
is calculated again as
</p>

<p>
\[\max \left( \frac{t}{mn\log(n)} \right)\]
</p>

<div id="orgdbef7a6" class="figure">
<p><img src="./imgs/Stoer and Wagner.png" alt="Stoer and Wagner.png">
</p>
<p><span class="figure-number">Figure 2: </span>Stoer and Wagner run times against input size (nodes and edges)</p>
</div>

<p>
By plotting the run times against the input sizes (nodes and
vertices) we can see that the plot follows the surface of the
complexity function.
</p>
</div>
</div>
</div>

<div id="outline-container-orgd89e251" class="outline-2">
<h2 id="orgd89e251">Hybrid approach</h2>
<div class="outline-text-2" id="text-orgd89e251">
<p>
An Hybrid approach consist into merging the two approaches (Karger
and Stein and Stoer and Wagner): the algorithm contracts the graph
until there are \(t = \frac{n}{\sqrt{2}}+1\) nodes, from there, Stoer
and Wagner is run on the contracted graph.
</p>

<p>
To study the complexity we can take look at the hybrid procedure:
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #00c089; font-weight: bold;">def</span> <span style="color: #7fc500;">hybrid</span>(graph):
    <span style="color: #78afff;">n</span> = graph.n_vertices
    <span style="color: #b7a07f; font-style: italic;"># </span><span style="color: #b7a07f; font-style: italic;">t = O(long(n))</span>
    <span style="color: #78afff;">t</span> = <span style="color: #3fb83f; font-weight: bold;">int</span>(np.ceil((n / (n-1)) * np.log(n))
    amin = np.Inf
    d_time = 0
    <span style="color: #00c089; font-weight: bold;">for</span> i <span style="color: #00c089; font-weight: bold;">in</span> <span style="color: #3fb83f; font-weight: bold;">range</span>(t):
        cut, d_time = hybrid_iteration(graph)
        <span style="color: #00c089; font-weight: bold;">if</span> cut &lt; amin:
            amin = cut
            d_time = perf_counter_ns()
    <span style="color: #00c089; font-weight: bold;">return</span> amin, d_time
</pre>
</div>
<p>
where the hybrid iteration is described as
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #00c089; font-weight: bold;">def</span> <span style="color: #7fc500;">hybrid_iteration</span>(graph):
    <span style="color: #78afff;">t</span> = np.ceil(graph.n_vertices / np.sqrt(2) + 1)
    <span style="color: #78afff;">g</span> = contract(graph, t)
    <span style="color: #00c089; font-weight: bold;">return</span> stoer_wagner(g)
</pre>
</div>
<p>
one <code>hybrid_iteration</code> consists in a contraction of the given graph,
then from that contraction we run the Stoer and Wagner
algorithm. Since the contraction is just a single loop running \(t =
  \frac{n}{\sqrt{2}} + 1\) times, <code>contract(graph,t)</code> is
\(O(n)\). Stoer and Wagner on the resulting graph is
\(O(mn\log(n))\) by hypothesis.
</p>
</div>


<div id="outline-container-orgc173b86" class="outline-3">
<h3 id="orgc173b86">How many times run the iteration</h3>
<div class="outline-text-3" id="text-orgc173b86">
<p>
If we consider
</p>

<p>
\[X_i = \text{the \(i\)-th iteration has contracted a minimum cuts'edge}\]
</p>

<p>
we can have
</p>

<p>
\[X = \sum_{i=0}^k X_i\]
</p>

<p>
the sum of independent random variables that states how many times
the random contraction have contracted the minimum cut of the
graph. We know from hypothesis of Karger Stein algorithm, that
</p>

<p>
\[P(X_i = 1) \leq \frac{1}{2}\]
</p>

<p>
and by taking \(P(X_i = 1) = \frac{1}{2}\) as assumption we can
find a lower bound on the number of iterations needed in order to
find w.h.p. the minimum cut. We know that, on \(k\) iterations
</p>

<p>
\[\mu = E[X] = \sum_{i=0}^k E[X_i] = \sum_{i=0}^k \frac{1}{2} = \frac{k}{2} \]
</p>

<p>
And we want to find \(k\) s.t.
</p>

<p>
\[P\left(\frac{|\beta - \alpha|}{\alpha} > \epsilon \right) \leq O\left(\frac{1}{n}\right)\]
</p>

<p>
We can use the chernoff bound
</p>

<p>
\[P\left(|X - \mu| > \mu \delta \right) \leq 2e^{-\frac{\mu \delta^2}{3}}\]
</p>

<p>
that works for \(\delta \in (0,1]\) with \(\mu = \frac{k}{2}\). We
conclude that, with \(k = \frac{4}{\epsilon^2}\log(n)\) we can
say that
</p>

<p>
\[2 e^{-\frac{k\epsilon^2}{4}} = \frac{2}{n} = O\left( \frac{1}{n} \right)\]
</p>

<p>
So the same bound as for Karger and Stein applies, and the
algorithm has complexity
</p>

<p>
\[O\left(mn\log^2(n)\right)\]
</p>
</div>
</div>


<div id="outline-container-org34825d2" class="outline-3">
<h3 id="org34825d2">Results</h3>
<div class="outline-text-3" id="text-org34825d2">

<div id="org402ebb1" class="figure">
<p><img src="./imgs/Hybrid.png" alt="Hybrid.png">
</p>
<p><span class="figure-number">Figure 3: </span>Hybrid run times against input size (nodes and edges)</p>
</div>

<p>
By plotting the run times against the input size (nodes and edges)
we can see that they follow the surface induced by the complexity
function of the algorithm.
</p>
</div>
</div>
</div>

<div id="outline-container-org55b6c63" class="outline-2">
<h2 id="org55b6c63">Conclusions</h2>
<div class="outline-text-2" id="text-org55b6c63">
</div>
<div id="outline-container-orgd19694f" class="outline-3">
<h3 id="orgd19694f">On efficiency</h3>
<div class="outline-text-3" id="text-orgd19694f">
<p>
<a id="orgfa46117"></a>
By purely relying on the complexity analysis of the algorithms we
should be able to see how the Karger and stein algorithm should
perform worse than Stoer and Wagner and the Hybrid approach, which
have instead comparable complexities. By plotting the run time of
each algorithm:
</p>

<div id="orge9a131b" class="figure">
<p><img src="./imgs/Runtime comp.png" alt="Runtime comp.png">
</p>
<p><span class="figure-number">Figure 4: </span>Runtime comparison between the three algorithms</p>
</div>

<p>
By looking closely to the graph we can see how the results meet our
expectations: Karger and Stein perform generally worse than Stoer
and Wagner, that performs in a similar way to our approach.
</p>
</div>
</div>

<div id="outline-container-org8714a1b" class="outline-3">
<h3 id="org8714a1b">On discovery time</h3>
<div class="outline-text-3" id="text-org8714a1b">
<p>
<a id="org7d755ae"></a>
Discovery time tells us another story. Even though Karger and Stein
performs badly compare to the other two algorithms, the discovery
time for the graphs in the dataset is not that worse compared to
the discovery time of the hybrid algorithm. Stoer and Wagner
outperforms the two even from this point of view, showing how is a
generally faster algorithm.
</p>

<div id="org1f3ee7e" class="figure">
<p><img src="./imgs/Discovery comp.png" alt="Discovery comp.png" width="500px">
</p>
<p><span class="figure-number">Figure 5: </span>Discovery time comparison between the three algorithms</p>
</div>
</div>
</div>
</div>
</div>
<div id="postamble" class="status">
<p class="author">Author: Luca Zaninotto</p>
<p class="date">Created: 2023-02-23 Thu 22:29</p>
<p class="validation"><a href="https://validator.w3.org/check?uri=referer">Validate</a></p>
</div>
</body>
</html>
